{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _STATISTICS ADVANCE 2_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_1. Explain the properties of the F-distribution._**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F-distribution is a probability distribution that arises frequently in statistical tests, particularly in the analysis of variance (ANOVA). Below are its key properties:\n",
    "\n",
    "- **Non-Negative**: The F-distribution is defined only for positive values. This is because it is a ratio of variances, which are always non-negative.\n",
    "- **Asymmetry**: The F-distribution is positively skewed, with the degree of skewness depending on the degrees of freedom in the numerator (\\(d_1\\)) and denominator (\\(d_2\\)).\n",
    "- **Degrees of Freedom**: The shape of the F-distribution is determined by two parameters: \\(d_1\\) (degrees of freedom of the numerator) and \\(d_2\\) (degrees of freedom of the denominator).\n",
    "- **Right-Tailed**: Most tests using the F-distribution are right-tailed because we are interested in whether the observed variance is significantly larger than expected.\n",
    "- **Mean and Variance**:\n",
    "  - Mean: The mean of the F-distribution is approximately \\( \\frac{d_2}{d_2 - 2} \\) for \\(d_2 > 2\\).\n",
    "  - Variance: The variance of the F-distribution is \\( \\frac{2d_2^2(d_1 + d_2 - 2)}{d_1(d_2 - 2)^2(d_2 - 4)} \\) for \\(d_2 > 4\\).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **_2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F-distribution is primarily used in the following statistical tests:\n",
    "\n",
    "- **Analysis of Variance (ANOVA)**:\n",
    "  - Used to test whether the means of multiple groups are significantly different.\n",
    "  - The F-distribution is appropriate because it compares the ratio of between-group variance to within-group variance.\n",
    "\n",
    "- **F-Test for Variances**:\n",
    "  - Used to compare the variances of two populations.\n",
    "  - The F-distribution is suitable because it models the ratio of two sample variances.\n",
    "\n",
    "- **Regression Analysis**:\n",
    "  - The F-test in regression evaluates the overall significance of a regression model by comparing the explained variance to unexplained variance.\n",
    "\n",
    "### Why Itâ€™s Appropriate:\n",
    "The F-distribution is appropriate because it models the ratio of variances, which is central to these tests. It helps determine whether observed differences are due to random chance or true effects.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_3. What are the key assumptions required for conducting an F-test to compare the variances of two populations?_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F-test to compare variances relies on several key assumptions:\n",
    "\n",
    "1. **Normality**: The data in both populations should follow a normal distribution.\n",
    "2. **Independence**: The samples from the two populations must be independent of each other.\n",
    "3. **Random Sampling**: The data should be collected through random sampling.\n",
    "4. **Homogeneity of Variances**: Although the test checks for this, the assumption applies to certain tests where F-values are used in subsequent steps.\n",
    "\n",
    "Violations of these assumptions may lead to incorrect conclusions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_4. What is the purpose of ANOVA, and how does it differ from a t-test?_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of ANOVA:\n",
    "ANOVA (Analysis of Variance) is used to test whether there are significant differences among the means of three or more groups. It helps determine if at least one group mean is significantly different without testing every pair individually.\n",
    "\n",
    "### Differences Between ANOVA and t-Test:\n",
    "- **Number of Groups**:\n",
    "  - t-Test: Compares the means of two groups.\n",
    "  - ANOVA: Compares the means of three or more groups.\n",
    "- **Error Rate**:\n",
    "  - t-Test: Conducting multiple t-tests increases the Type I error rate.\n",
    "  - ANOVA: Controls the Type I error rate by testing all groups simultaneously.\n",
    "- **Output**:\n",
    "  - t-Test: Provides a direct comparison of two means.\n",
    "  - ANOVA: Provides an overall test of differences among group means.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups._**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use One-Way ANOVA:\n",
    "Use one-way ANOVA when comparing the means of three or more groups that are categorized by a single independent variable.\n",
    "\n",
    "### Why Use One-Way ANOVA:\n",
    "- **Type I Error Control**: Conducting multiple t-tests increases the risk of Type I error (false positives). One-way ANOVA addresses this issue by testing all group means simultaneously.\n",
    "- **Efficiency**: One-way ANOVA provides a single test for group differences rather than performing multiple pairwise comparisons.\n",
    "- **Insights**: ANOVA identifies overall differences among groups, which can be followed up with post-hoc tests if needed.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning of Variance:\n",
    "- **Total Variance**: The total variance in the data is divided into two components:\n",
    "  - **Between-Group Variance**: Measures the variability due to differences between the group means.\n",
    "  - **Within-Group Variance**: Measures the variability within each group due to individual differences.\n",
    "\n",
    "### Contribution to the F-Statistic:\n",
    "- The F-statistic is calculated as the ratio of between-group variance to within-group variance:\n",
    "  \\[\n",
    "  F = \\frac{\\text{Between-Group Variance}}{\\text{Within-Group Variance}}\n",
    "  \\]\n",
    "- A large F-value indicates that between-group variability is significantly greater than within-group variability, suggesting that at least one group mean differs significantly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Differences:\n",
    "\n",
    "| Aspect                     | Frequentist ANOVA                       | Bayesian ANOVA                           |\n",
    "|----------------------------|-----------------------------------------|-----------------------------------------|\n",
    "| **Uncertainty**            | Uses p-values and confidence intervals to handle uncertainty. | Models uncertainty directly using probability distributions. |\n",
    "| **Parameter Estimation**   | Estimates fixed parameters (e.g., means, variances) based on sample data. | Uses prior distributions combined with sample data (posterior distributions). |\n",
    "| **Hypothesis Testing**     | Tests a null hypothesis (e.g., all means are equal) using F-statistics and p-values. | Tests hypotheses by calculating posterior probabilities or Bayes factors. |\n",
    "| **Interpretation**         | Results are interpreted in terms of rejecting or failing to reject the null hypothesis. | Results are interpreted probabilistically, such as the probability of one model being true compared to another. |\n",
    "| **Assumptions**            | Relies heavily on assumptions like normality and independence. | Can incorporate prior knowledge and is often more robust to violations of assumptions. |\n",
    "\n",
    "### Conclusion:\n",
    "The Bayesian approach provides a more flexible framework by incorporating prior knowledge and offering probabilistic interpretations. However, it is computationally intensive and requires careful specification of priors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_8. Question: You have two sets of data representing the incomes of two different professions:_**\n",
    "- Profession A: [48, 52, 55, 60, 62]\n",
    "- Profession B: [45, 50, 55, 52, 47]                          \n",
    "\n",
    "**Perform an F-test to determine if the variances of the two professions' incomes are equal. What are your conclusions based on the F-test?**\n",
    "\n",
    "**Task:** Use Python to calculate the F-statistic and p-value for the given data.\n",
    "\n",
    "__Objective:__ Gain experience in performing F-tests and interpreting the results in terms of variance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of Profession A: 32.8\n",
      "Variance of Profession B: 15.7\n",
      "F-Statistic: 2.089171974522293\n",
      "p-value: 0.49304859900533904\n",
      "Conclusion: Fail to reject the null hypothesis. Variances are equal.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "\n",
    "# Data for both professions\n",
    "profession_a = [48, 52, 55, 60, 62]\n",
    "profession_b = [45, 50, 55, 52, 47]\n",
    "\n",
    "# Step 1: Calculate the variances of both datasets\n",
    "var_a = np.var(profession_a, ddof=1)  # Variance of Profession A (sample variance)\n",
    "var_b = np.var(profession_b, ddof=1)  # Variance of Profession B (sample variance)\n",
    "\n",
    "# Step 2: Calculate the F-statistic\n",
    "f_statistic = var_a / var_b if var_a >= var_b else var_b / var_a\n",
    "\n",
    "# Step 3: Degrees of freedom for both groups\n",
    "dof_a = len(profession_a) - 1\n",
    "dof_b = len(profession_b) - 1\n",
    "\n",
    "# Step 4: Calculate the p-value\n",
    "p_value = 2 * (1 - f.cdf(f_statistic, dof_a, dof_b))  # Two-tailed p-value\n",
    "\n",
    "# Output the results\n",
    "print(\"Variance of Profession A:\", var_a)\n",
    "print(\"Variance of Profession B:\", var_b)\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Conclusion: Reject the null hypothesis. Variances are not equal.\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to reject the null hypothesis. Variances are equal.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **_9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data:_**\n",
    "- Region A: [160, 162, 165, 158, 164]\n",
    "- Region B: [172, 175, 170, 168, 174]\n",
    "- Region C: [180, 182, 179, 185, 183]\n",
    "\n",
    "__Task: Write Python code to perform the one-way ANOVA and interpret the results__\n",
    "\n",
    "__Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 67.87330316742101\n",
      "p-value: 2.8706641879370266e-07\n",
      "Conclusion: Reject the null hypothesis. There is a significant difference in the average heights between the regions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data for the heights in three regions\n",
    "region_a = [160, 162, 165, 158, 164]\n",
    "region_b = [172, 175, 170, 168, 174]\n",
    "region_c = [180, 182, 179, 185, 183]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(region_a, region_b, region_c)\n",
    "\n",
    "# Output the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpretation of the results\n",
    "alpha = 0.05  # Significance level\n",
    "if p_value < alpha:\n",
    "    print(\"Conclusion: Reject the null hypothesis. There is a significant difference in the average heights between the regions.\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to reject the null hypothesis. There is no significant difference in the average heights between the regions.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
